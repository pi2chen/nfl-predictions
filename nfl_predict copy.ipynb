{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('nfl-cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('Date')\n",
    "\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must now compute the expanding averages over previous games in order to train\n",
    "and test our model. $\\newline$\n",
    "This is because we can only use statistics from previous \n",
    "games to predict our incoming test game. $\\newline$\n",
    "We use expanding instead of rolling averages because we want the expanding mean\n",
    "over all previous games, not just a fixed sliding window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Team1Won</th>\n",
       "      <th>Season</th>\n",
       "      <th>Date</th>\n",
       "      <th>Team1</th>\n",
       "      <th>Team2</th>\n",
       "      <th>Home</th>\n",
       "      <th>Team1Pts</th>\n",
       "      <th>...</th>\n",
       "      <th>Team1RushAtt</th>\n",
       "      <th>Team2RushAtt</th>\n",
       "      <th>Team1RushYds</th>\n",
       "      <th>Team2RushYds</th>\n",
       "      <th>Team1RYM</th>\n",
       "      <th>Team2RYM</th>\n",
       "      <th>Team1PYM</th>\n",
       "      <th>Team2PYM</th>\n",
       "      <th>Team1YM</th>\n",
       "      <th>Team2YM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1459</td>\n",
       "      <td>False</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-09-11</td>\n",
       "      <td>DAL</td>\n",
       "      <td>TAM</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>71</td>\n",
       "      <td>152</td>\n",
       "      <td>-81</td>\n",
       "      <td>81</td>\n",
       "      <td>-22</td>\n",
       "      <td>22</td>\n",
       "      <td>-103</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>1383</td>\n",
       "      <td>True</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>DAL</td>\n",
       "      <td>NYG</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>176</td>\n",
       "      <td>167</td>\n",
       "      <td>9</td>\n",
       "      <td>-9</td>\n",
       "      <td>46</td>\n",
       "      <td>-46</td>\n",
       "      <td>55</td>\n",
       "      <td>-55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>1359</td>\n",
       "      <td>True</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-10-02</td>\n",
       "      <td>DAL</td>\n",
       "      <td>WAS</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>62</td>\n",
       "      <td>142</td>\n",
       "      <td>-80</td>\n",
       "      <td>80</td>\n",
       "      <td>62</td>\n",
       "      <td>-62</td>\n",
       "      <td>-18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>1341</td>\n",
       "      <td>True</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-10-09</td>\n",
       "      <td>DAL</td>\n",
       "      <td>LAR</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>163</td>\n",
       "      <td>38</td>\n",
       "      <td>125</td>\n",
       "      <td>-125</td>\n",
       "      <td>-209</td>\n",
       "      <td>209</td>\n",
       "      <td>-84</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>1309</td>\n",
       "      <td>False</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-10-16</td>\n",
       "      <td>DAL</td>\n",
       "      <td>PHI</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>134</td>\n",
       "      <td>136</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>-49</td>\n",
       "      <td>47</td>\n",
       "      <td>-47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  Unnamed: 0    ID  Team1Won  Season        Date Team1 Team2  Home  \\\n",
       "6       6           6  1459     False    2022  2022-09-11   DAL   TAM     1   \n",
       "47     47          47  1383      True    2022  2022-09-26   DAL   NYG     0   \n",
       "53     53          53  1359      True    2022  2022-10-02   DAL   WAS     1   \n",
       "74     74          74  1341      True    2022  2022-10-09   DAL   LAR     0   \n",
       "88     88          88  1309     False    2022  2022-10-16   DAL   PHI     0   \n",
       "\n",
       "    Team1Pts  ...  Team1RushAtt  Team2RushAtt  Team1RushYds  Team2RushYds  \\\n",
       "6          3  ...            18            33            71           152   \n",
       "47        23  ...            30            25           176           167   \n",
       "53        25  ...            29            27            62           142   \n",
       "74        22  ...            34            15           163            38   \n",
       "88        17  ...            26            39           134           136   \n",
       "\n",
       "    Team1RYM  Team2RYM  Team1PYM  Team2PYM  Team1YM  Team2YM  \n",
       "6        -81        81       -22        22     -103      103  \n",
       "47         9        -9        46       -46       55      -55  \n",
       "53       -80        80        62       -62      -18       18  \n",
       "74       125      -125      -209       209      -84       84  \n",
       "88        -2         2        49       -49       47      -47  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Team1'] == 'DAL'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the expanding averages over previous games. \n",
    "\n",
    "numeric_columns = ['Home',\n",
    "\t\t\t\t'Team1Pts',    \n",
    "\t\t\t\t'Team2Pts',    \n",
    "\t\t\t\t'Team1PtDiff',\n",
    "\t\t\t\t'Team2PtDiff', \n",
    "\t\t\t\t'Team1TM',    \n",
    "\t\t\t\t'Team2TM',     \n",
    "\t\t\t\t'Team1Rating', \n",
    "\t\t\t\t'Team2Rating', \n",
    "\t\t\t\t'Team1Sks',    \n",
    "\t\t\t\t'Team2Sks',    \n",
    "\t\t\t\t'Team1SkYds',  \n",
    "\t\t\t\t'Team2SkYds',  \n",
    "\t\t\t\t'Team1RushAtt',\n",
    "\t\t\t\t'Team2RushAtt',\n",
    "\t\t\t\t'Team1RushYds',\n",
    "\t\t\t\t'Team2RushYds',\n",
    "\t\t\t\t'Team1RYM',    \n",
    "\t\t\t\t'Team2RYM',    \n",
    "\t\t\t\t'Team1PYM',    \n",
    "\t\t\t\t'Team2PYM',    \n",
    "\t\t\t\t'Team1YM',     \n",
    "\t\t\t\t'Team2YM']\n",
    "\n",
    "for column in numeric_columns:\n",
    "\tavg_col_name = column + '_avg'\n",
    "\tdf[avg_col_name] = (\n",
    "\t\tdf.groupby('Team1', group_keys=False)[column]\n",
    "\t\t.apply(lambda group: group.expanding().mean().shift(1))\n",
    "\t\t.reset_index(drop=True)\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Team1Won</th>\n",
       "      <th>Season</th>\n",
       "      <th>Date</th>\n",
       "      <th>Team1</th>\n",
       "      <th>Team2</th>\n",
       "      <th>Home</th>\n",
       "      <th>Team1Pts</th>\n",
       "      <th>...</th>\n",
       "      <th>Team1RushAtt_avg</th>\n",
       "      <th>Team2RushAtt_avg</th>\n",
       "      <th>Team1RushYds_avg</th>\n",
       "      <th>Team2RushYds_avg</th>\n",
       "      <th>Team1RYM_avg</th>\n",
       "      <th>Team2RYM_avg</th>\n",
       "      <th>Team1PYM_avg</th>\n",
       "      <th>Team2PYM_avg</th>\n",
       "      <th>Team1YM_avg</th>\n",
       "      <th>Team2YM_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1459</td>\n",
       "      <td>False</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-09-11</td>\n",
       "      <td>DAL</td>\n",
       "      <td>TAM</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>1383</td>\n",
       "      <td>True</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>DAL</td>\n",
       "      <td>NYG</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>71.0</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>-81.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>-22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>-103.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>1359</td>\n",
       "      <td>True</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-10-02</td>\n",
       "      <td>DAL</td>\n",
       "      <td>WAS</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>123.5</td>\n",
       "      <td>159.500000</td>\n",
       "      <td>-36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>1341</td>\n",
       "      <td>True</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-10-09</td>\n",
       "      <td>DAL</td>\n",
       "      <td>LAR</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>25.666667</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>103.0</td>\n",
       "      <td>153.666667</td>\n",
       "      <td>-50.666667</td>\n",
       "      <td>50.666667</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>-28.666667</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>1309</td>\n",
       "      <td>False</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-10-16</td>\n",
       "      <td>DAL</td>\n",
       "      <td>PHI</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>27.750000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>118.0</td>\n",
       "      <td>124.750000</td>\n",
       "      <td>-6.750000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>-30.750000</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>-37.5</td>\n",
       "      <td>37.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  Unnamed: 0    ID  Team1Won  Season        Date Team1 Team2  Home  \\\n",
       "6       6           6  1459     False    2022  2022-09-11   DAL   TAM     1   \n",
       "47     47          47  1383      True    2022  2022-09-26   DAL   NYG     0   \n",
       "53     53          53  1359      True    2022  2022-10-02   DAL   WAS     1   \n",
       "74     74          74  1341      True    2022  2022-10-09   DAL   LAR     0   \n",
       "88     88          88  1309     False    2022  2022-10-16   DAL   PHI     0   \n",
       "\n",
       "    Team1Pts  ...  Team1RushAtt_avg  Team2RushAtt_avg  Team1RushYds_avg  \\\n",
       "6          3  ...               NaN               NaN               NaN   \n",
       "47        23  ...         18.000000         33.000000              71.0   \n",
       "53        25  ...         24.000000         29.000000             123.5   \n",
       "74        22  ...         25.666667         28.333333             103.0   \n",
       "88        17  ...         27.750000         25.000000             118.0   \n",
       "\n",
       "    Team2RushYds_avg  Team1RYM_avg  Team2RYM_avg  Team1PYM_avg  Team2PYM_avg  \\\n",
       "6                NaN           NaN           NaN           NaN           NaN   \n",
       "47        152.000000    -81.000000     81.000000    -22.000000     22.000000   \n",
       "53        159.500000    -36.000000     36.000000     12.000000    -12.000000   \n",
       "74        153.666667    -50.666667     50.666667     28.666667    -28.666667   \n",
       "88        124.750000     -6.750000      6.750000    -30.750000     30.750000   \n",
       "\n",
       "    Team1YM_avg  Team2YM_avg  \n",
       "6           NaN          NaN  \n",
       "47       -103.0        103.0  \n",
       "53        -24.0         24.0  \n",
       "74        -22.0         22.0  \n",
       "88        -37.5         37.5  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Team1'] == 'DAL'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Team1Won</th>\n",
       "      <th>Season</th>\n",
       "      <th>Date</th>\n",
       "      <th>Team1</th>\n",
       "      <th>Team2</th>\n",
       "      <th>Home</th>\n",
       "      <th>Team1Pts</th>\n",
       "      <th>...</th>\n",
       "      <th>Team1RushAtt_avg</th>\n",
       "      <th>Team2RushAtt_avg</th>\n",
       "      <th>Team1RushYds_avg</th>\n",
       "      <th>Team2RushYds_avg</th>\n",
       "      <th>Team1RYM_avg</th>\n",
       "      <th>Team2RYM_avg</th>\n",
       "      <th>Team1PYM_avg</th>\n",
       "      <th>Team2PYM_avg</th>\n",
       "      <th>Team1YM_avg</th>\n",
       "      <th>Team2YM_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1459</td>\n",
       "      <td>False</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-09-11</td>\n",
       "      <td>DAL</td>\n",
       "      <td>TAM</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>71.0</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>-81.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>-22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>-103.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>1383</td>\n",
       "      <td>True</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>DAL</td>\n",
       "      <td>NYG</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>71.0</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>-81.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>-22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>-103.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>1359</td>\n",
       "      <td>True</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-10-02</td>\n",
       "      <td>DAL</td>\n",
       "      <td>WAS</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>123.5</td>\n",
       "      <td>159.500000</td>\n",
       "      <td>-36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>1341</td>\n",
       "      <td>True</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-10-09</td>\n",
       "      <td>DAL</td>\n",
       "      <td>LAR</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>25.666667</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>103.0</td>\n",
       "      <td>153.666667</td>\n",
       "      <td>-50.666667</td>\n",
       "      <td>50.666667</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>-28.666667</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>1309</td>\n",
       "      <td>False</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-10-16</td>\n",
       "      <td>DAL</td>\n",
       "      <td>PHI</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>27.750000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>118.0</td>\n",
       "      <td>124.750000</td>\n",
       "      <td>-6.750000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>-30.750000</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>-37.5</td>\n",
       "      <td>37.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  Unnamed: 0    ID  Team1Won  Season        Date Team1 Team2  Home  \\\n",
       "6       6           6  1459     False    2022  2022-09-11   DAL   TAM     1   \n",
       "47     47          47  1383      True    2022  2022-09-26   DAL   NYG     0   \n",
       "53     53          53  1359      True    2022  2022-10-02   DAL   WAS     1   \n",
       "74     74          74  1341      True    2022  2022-10-09   DAL   LAR     0   \n",
       "88     88          88  1309     False    2022  2022-10-16   DAL   PHI     0   \n",
       "\n",
       "    Team1Pts  ...  Team1RushAtt_avg  Team2RushAtt_avg  Team1RushYds_avg  \\\n",
       "6          3  ...         18.000000         33.000000              71.0   \n",
       "47        23  ...         18.000000         33.000000              71.0   \n",
       "53        25  ...         24.000000         29.000000             123.5   \n",
       "74        22  ...         25.666667         28.333333             103.0   \n",
       "88        17  ...         27.750000         25.000000             118.0   \n",
       "\n",
       "    Team2RushYds_avg  Team1RYM_avg  Team2RYM_avg  Team1PYM_avg  Team2PYM_avg  \\\n",
       "6         152.000000    -81.000000     81.000000    -22.000000     22.000000   \n",
       "47        152.000000    -81.000000     81.000000    -22.000000     22.000000   \n",
       "53        159.500000    -36.000000     36.000000     12.000000    -12.000000   \n",
       "74        153.666667    -50.666667     50.666667     28.666667    -28.666667   \n",
       "88        124.750000     -6.750000      6.750000    -30.750000     30.750000   \n",
       "\n",
       "    Team1YM_avg  Team2YM_avg  \n",
       "6        -103.0        103.0  \n",
       "47       -103.0        103.0  \n",
       "53        -24.0         24.0  \n",
       "74        -22.0         22.0  \n",
       "88        -37.5         37.5  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Should we drop the first column or impute with its original values?\n",
    "\n",
    "for column in numeric_columns:\n",
    "\tavg_col_name = column + '_avg'\n",
    "\tdf[avg_col_name] = df[avg_col_name].fillna(df[column])\n",
    "\n",
    "df[df['Team1'] == 'DAL'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's hold out a test set and set it aside for later use. $\\newline$\n",
    "Note that we can simply split the dataframe because it has already been sorted in chronological order, meaning that data leakage for the time series logic will **not** occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_set, test_set = np.split(df, [int(0.8 * len(df))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do cross validation and training!\n",
    "\n",
    "The function below sets up training and testing data for each fold of a time series split. It begins by defining column groups: `train_post_game_cols` holds post-game statistics like points and rushing yards, while `test_post_game_col` contains the same stats but with `_avg` appended, representing averages for testing. The function takes a specific fold (training and testing indices) and a dataframe as input, then uses these indices to split the dataframe into training and testing sets. Features and outcome labels are extracted separately for training (`X_train` and `y_train`) and testing (`X_test` and `y_test`). The function ensures the split data is ready for training and evaluation during the cross-validation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train and test sets for each fold of TimeSeriesSplit\n",
    "\n",
    "pre_game_cols = ['Team1', 'Team2', 'Home']\n",
    "train_post_game_cols = ['Team1Pts', 'Team2Pts', 'Team1RushYds', 'Team2RushYds', 'Team1SkYds', 'Team2SkYds',\n",
    "                  'Team1Sks', 'Team2Sks', 'Team1RushAtt', 'Team2RushAtt', 'Team1RYM', 'Team2RYM', \n",
    "                  'Team1PYM', 'Team2PYM', 'Team1YM', 'Team2YM', 'Team1Rating', 'Team2Rating']\n",
    "\n",
    "test_post_game_cols = [col + '_avg' for col in train_post_game_cols]\n",
    "\n",
    "outcome_col = 'Team1Won'\n",
    "\n",
    "def prep_data_for_fold(fold, df):\n",
    "  \n",
    "  # Split data into training and testing based on the fold\n",
    "  train_indices, test_indices = fold\n",
    "  train_data = df.iloc[train_indices]\n",
    "  test_data = df.iloc[test_indices]\n",
    "\n",
    "  # Extract features that will be trained and tested on\n",
    "  X_train = train_data[train_post_game_cols]\n",
    "  X_test = test_data[test_post_game_cols]\n",
    "  \n",
    "  # Class labels from fold split\n",
    "  y_train = train_data[outcome_col]\n",
    "  y_test = test_data[outcome_col]\n",
    "  \n",
    "  return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below calculates how well a model performs on the NFL time series dataset using a nested cross-validation setup. It uses a `TimeSeriesSplit` with 5 splits to preserve the order of time-dependent data. For each fold, it splits the data into training and testing sets and prepares the features and labels using `prep_data_for_fold`. Columns in the test set ending with `_avg` are renamed to match their training counterparts. The function scales the data by fitting a `StandardScaler` on the training set and applying it to both training and testing data. Then, it runs a `GridSearchCV` on the training set to find the best hyperparameters for the model. The best-performing model from the grid search is used to make predictions on the test set, and its accuracy is calculated and stored. After completing all folds, the function returns the average accuracy and prints the best model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# TODO: PCA???\n",
    "# TODO: Run SequentialFeatureSelector to only use best features?\n",
    "\n",
    "# Nested cross-validation loop that computes how well a model does.\n",
    "# Return an accuracy score averaged over all folds of the TimeSeriesSplit.\n",
    "\n",
    "best_models = []\n",
    "\n",
    "def get_model_accuracy(model, params, df):\n",
    "\n",
    "  tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "  accuracies = []\n",
    "\n",
    "  # Outer loop: find average accuracy over all time series splits\n",
    "\n",
    "  for train_indices, test_indices in tscv.split(df):\n",
    "\n",
    "    # Prepare the data for this fold\n",
    "    X_train, X_test, y_train, y_test = prep_data_for_fold((train_indices, test_indices), df)\n",
    "\n",
    "    # Rename the <col>_avg columns to just <col> so GridSearchCV doesn't complain\n",
    "    X_test = X_test.rename(columns=lambda x: x[:-4] if x.endswith('_avg') else x)\n",
    "\n",
    "    # Scale the data (fit scaler on training data and transform both train and test)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Inner loop: find the best hyperparameters for this split\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=params, cv=tscv)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best model from grid search\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Analyze how well model does by comparing its predictions to actual class labels\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "  best_models.append(best_model)\n",
    "  \n",
    "  print(best_model)\n",
    "\n",
    "  # Return the average accuracy across all outer folds\n",
    "  return sum(accuracies) / len(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=15, max_features=15, min_samples_leaf=5)\n",
      "0.5626016260162602\n",
      "LogisticRegression(C=0.1, penalty='l1', solver='saga')\n",
      "0.6097560975609756\n",
      "KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
      "0.5772357723577235\n",
      "SVC(C=1, degree=2, kernel='linear')\n",
      "0.6032520325203252\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "models_dict = {}\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc_params = {\n",
    "  'max_depth': [5, 10, 15, 20],\n",
    "  'max_features': [5, 10, 15],\n",
    "  'min_samples_leaf': [5, 10, 15, 20]\n",
    "}\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr_params = {\n",
    "\t'penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "\t'C': [0.1, 1, 10],\n",
    "\t'solver': ['liblinear', 'saga'],\n",
    "\t'max_iter': [100, 200]\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc_params = {\n",
    "  'n_estimators': [50, 100, 200],\n",
    "  'max_depth': [None, 10, 20],\n",
    "  'min_samples_split': [2, 5, 10],\n",
    "  'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc_params = {\n",
    "  'n_estimators': [50, 100, 200],\n",
    "  'learning_rate': [0.01, 0.1, 0.2],\n",
    "  'max_depth': [3, 5, 7],\n",
    "  'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn_params = {\n",
    "  'n_neighbors': [3, 5, 10],\n",
    "  'weights': ['uniform', 'distance'],\n",
    "  'p': [1, 2]  # 1 = Manhattan distance, 2 = Euclidean distance\n",
    "}\n",
    "\n",
    "svc = SVC()\n",
    "svc_params = {\n",
    "  'C': [0.1, 1, 10],\n",
    "  'kernel': ['linear', 'rbf', 'poly'],\n",
    "  'gamma': ['scale', 'auto'],\n",
    "  'degree': [2, 3, 4]  # Only for 'poly' kernel\n",
    "}\n",
    "\n",
    "models_dict[dtc] = dtc_params\n",
    "models_dict[lr] = lr_params\n",
    "# models_dict[rfc] = rfc_params\n",
    "# models_dict[gbc] = gbc_params\n",
    "models_dict[knn] = knn_params\n",
    "models_dict[svc] = svc_params\n",
    "\n",
    "for model in models_dict.keys():\n",
    "  score = get_model_accuracy(model, models_dict[model], df)\n",
    "  print(score)\n",
    "\n",
    "# TODO: Handle <col>_avg NaN for each team's first game of the season\n",
    "# LogisticRegression() does not accept missing values encoded as NaN natively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a final evaluation of the model on the held out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model DecisionTreeClassifier(max_depth=15, max_features=15, min_samples_leaf=5): 0.527027027027027\n",
      "Accuracy of model LogisticRegression(C=0.1, penalty='l1', solver='saga'): 0.581081081081081\n",
      "Accuracy of model KNeighborsClassifier(n_neighbors=10, weights='distance'): 0.581081081081081\n",
      "Accuracy of model SVC(C=1, degree=2, kernel='linear'): 0.5675675675675675\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Let's say that LogisticRegression(C=0.1, penalty='l1', solver='saga') is the best model.\n",
    "\n",
    "lr = LogisticRegression(C=0.1, solver='saga', penalty='l1')\n",
    "\n",
    "for model in best_models:\n",
    "\tX_train = train_set[train_post_game_cols]\n",
    "\tX_test = test_set[test_post_game_cols].rename(columns=lambda x: x[:-4] if x.endswith('_avg') else x)\n",
    "\ty_train = train_set[outcome_col]\n",
    "\ty_test = test_set[outcome_col]\n",
    "\n",
    "\tscaler = StandardScaler()\n",
    "\tX_train = scaler.fit_transform(X_train)\n",
    "\tX_test = scaler.transform(X_test)\n",
    "\n",
    "\tmodel.fit(X_train, y_train)\n",
    "\ty_pred = model.predict(X_test)\n",
    "\taccuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\tprint(\"Accuracy of model \" + str(model) + \": \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "TP = conf_matrix[0, 0]\n",
    "FN = conf_matrix[0, 1]\n",
    "FP = conf_matrix[1, 0]\n",
    "TN = conf_matrix[1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(TP, FN, FP, TN):\n",
    "    table_data = [[TP,FN],[FP,TN]]\n",
    "    df = pd.DataFrame(table_data, columns =['Predicted 1','Predicted 0'])\n",
    "    df = df.rename(index={0: 'Actual 1', 1: 'Actual 0'})\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 1</th>\n",
       "      <th>Predicted 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>41</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 1  Predicted 0\n",
       "Actual 1           41           26\n",
       "Actual 0           38           43"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_confusion_matrix(TP, FN, FP, TN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
