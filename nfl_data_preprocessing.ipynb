{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Introduction**\n",
    "\n",
    "The goal of this project is to predict which NFL team will win a match based on their recent historical performance. This is a classification problem, where we aim to forecast the outcome (win or loss) of a game using historical team data and performance metrics.\n",
    "\n",
    "Predicting NFL game outcomes benefits:\n",
    "- **Coaches** by refining strategies,\n",
    "- **Analysts** by providing insights,\n",
    "- **Betting companies** by setting better odds, and\n",
    "- **Fans** by boosting engagement.\n",
    "\n",
    "By analyzing historical performance data, we can uncover patterns that inform decision-making for team preparation, betting strategies, and fan interactions. This improves outcomes for all stakeholders involved, from optimizing team tactics to generating content for fans.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in base data from csv\n",
    "df = pd.read_csv('nfl.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all rows and columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Cleaning & Exploration**\n",
    "Here is the general overview of the steps we took during data cleaning & exploration.\n",
    "\n",
    "- **Handle missing/invalid values**: Fill in or remove missin/invalid data to maintain dataset integrity.\n",
    "- **Standardize formats & data types & units**: Ensure consistency in date formats, data types, and measurement units.\n",
    "- **Remove unnecessary columns**: Drop irrelevant columns to simplify the dataset.\n",
    "- **Anomoly detection & filter outliers**: Identify and manage extreme values that may distort analysis.\n",
    "- **Correlation analysis**: Analyze relationships between variables to identify strong correlations that to inform feature selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Handle Missing/Invalid Values**\n",
    "To handle missing values, we count the number of null values in each column.\n",
    "- We can see that the data is quite complete, with no null values except in the away column.\n",
    "- Upon further inspection of the away column, it can be seen that the NaN value is used to denote that the current team is at home and the @ value is used to denote that the current team is away.\n",
    "- Therefore, we do not need to handle any missing values.\n",
    "\n",
    "Upon further data inspection, we found that some games ended in a tie.\n",
    "- We will be considering this an invalid type since we are only trying to predict a win or loss\n",
    "- Therefore, all rows which have a tie result will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "\n",
    "null_counts = df.isnull().sum()\n",
    "\n",
    "if (null_counts > 0).any():\n",
    "    print(null_counts[null_counts > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle invalid values\n",
    "\n",
    "df = df[~df['Result'].str[0].isin(['T'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Standardize Formats, Data Types, & Units**\n",
    "\n",
    "Before we complete the other steps in data cleaning, we should perform data standardization to make comparisons easier. This includes:\n",
    "- Check that each column has a consistent type.\n",
    "  - Our check found that each column had a consitent type except 'Away', which we handle in the next step.\n",
    "- Standardizing non-numeric / categorical data.\n",
    "  - Here we print out any columns without the 'int64' or 'float64' type.\n",
    "  - Then we go through each column and turn those into a standardized type.\n",
    "  - As a final check, we print the data type of each column and double check by inspecing the data.\n",
    "- Confirming consistent units.\n",
    "  - Since the source of the data provides units, they are expected to be consistent.\n",
    "  - However, this is further checked by a visual inspection of the data and any outliers/anomolies which may be detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that each column has a consistent type\n",
    "for column in df.columns:\n",
    "  if df[column].map(type).nunique() > 1:\n",
    "    print(f\"Column '{column}' contains mixed types.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing non-numeric data\n",
    "non_numeric_columns = df.select_dtypes(exclude=['int64', 'float64'])\n",
    "print(non_numeric_columns.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing non-numeric data\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "def convert_to_seconds(time_str):\n",
    "    minutes, seconds = map(int, time_str.split(':'))\n",
    "    return minutes * 60 + seconds\n",
    "df['ToP'] = df['ToP'].apply(convert_to_seconds)\n",
    "df['ToP.1'] = df['ToP.1'].apply(convert_to_seconds)\n",
    "\n",
    "df['Away'] = df['Away'].isna().astype(int)\n",
    "\n",
    "def convert_to_minutes(time_str):\n",
    "    return int(time_str.split(':')[0])\n",
    "df['Time'] = df['Time'].apply(convert_to_minutes)\n",
    "\n",
    "df['Result'] = df['Result'].str[0].map({'W': 1, 'L': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing non-numeric data\n",
    "non_numeric_columns = df.select_dtypes(exclude=['int64', 'float64'])\n",
    "print(non_numeric_columns.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing non-numeric data\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Remove Unnecessary Columns**\n",
    "\n",
    "To simplify our dataset, we should look to see if there are any unncessary columns. This can include:\n",
    "- Columns containing irrelavent information\n",
    "  - Upon inspection of the data, we can see that the 'Rk' column served as an index column. \n",
    "  - Therefore, the 'Rk' column can be considered to contain irrelavent information to out model and thus removed.\n",
    "- Columns with constant data\n",
    "  - No columns were found to have constant data\n",
    "- Columns with excessive missing data\n",
    "  - Since we have handled and discovered no missing values, we do not need to account for this case\n",
    "- Columns with identical data (we will keep the first column alphabetically for each duplicate)\n",
    "  - Column 'Att' is a duplicate of column 'Rush_Att'\n",
    "  - Column 'Att.1' is a duplicate of column 'Opp_Rush_Att'\n",
    "  - Column 'DY/P' is a duplicate of column 'DY/P.1'\n",
    "  - Column 'Pts' is a duplicate of column 'Pts.1'\n",
    "  - Column 'PtsO' is a duplicate of column 'PtsO.1'\n",
    "  - Column 'Rate' is a duplicate of column 'Rate.2'\n",
    "  - Column 'Rate.1' is a duplicate of column 'Rate.3'\n",
    "  - Column 'TO' is a duplicate of column 'TO.2'\n",
    "  - Column 'ToP' is a duplicate of column 'ToP.1'\n",
    "  - Column 'Y/P' is a duplicate of column 'Y/P.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns containing irrelavent information\n",
    "df.drop('Rk', axis=1, inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with constant data\n",
    "constant_columns = df.columns[df.nunique() == 1]\n",
    "print('Columns with constant data:', constant_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with identical data\n",
    "duplicate_columns = {}\n",
    "seen_pairs = set()\n",
    "\n",
    "for col1 in df.columns:\n",
    "  for col2 in df.columns:\n",
    "    if col1 != col2 and df[col1].equals(df[col2]):\n",
    "      if (col1, col2) not in seen_pairs and (col2, col1) not in seen_pairs:\n",
    "        duplicate_columns[col1] = col2\n",
    "        seen_pairs.add((col1, col2))\n",
    "\n",
    "sorted_duplicate_columns = sorted(duplicate_columns.items())\n",
    "\n",
    "for col, duplicate in sorted_duplicate_columns:\n",
    "  print(f\"Column '{col}' is a duplicate of column '{duplicate}'\")\n",
    "\n",
    "duplicated_columns_list = list(set(duplicate_columns.keys()).union(duplicate_columns.values()))\n",
    "print(df[duplicated_columns_list].head(5).T.sort_index(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with identical data\n",
    "for col1, duplicate in duplicate_columns.items():\n",
    " if duplicate in df.columns:\n",
    "    df.drop(duplicate, axis=1, inplace=True)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Anomoly Detection & Filter Outliers**\n",
    "\n",
    "Anomaly detection is essential to identify and address outliers or errors in the dataset.\n",
    "This helps to ensure that the analysis remains accurate and the model is not influenced by misleading or irrelevant data points. Note that this is also somewhat part of data exploration.\n",
    "We followed the steps below:\n",
    "\n",
    "- Plot distributions for numeric data\n",
    "\t- Before we search for anomolies, is good to visualize how the data is distributed\n",
    "\t- Additionally, we should note that some of the numeric values are inheriently categorical or continous such as:\n",
    "\t\t- Result\n",
    "\t\t\tSeason\n",
    "\t\t\tTime\n",
    "\t\t\tWeek\n",
    "\t\t\tG#\n",
    "- Using the plots, we can inspect to see the types of distributions\n",
    "\t- Only only classified Yds.1 and Yds.3 as \"exponential\"\n",
    "\t- Everything else is considered to have a \"normal\" distribution, even if severly skewed\n",
    "- By separetly calculating the Z-scores for normal and exponential features and combining them at the end:\n",
    "\t- We get an anomoly rate of 15.60% for Z-score threshold of 3 and 2.92% for Z-score threshold of 4\n",
    "\t- Printing out the anomolies for Z-score threshold of 4, we see games with still relatively normal stats\n",
    "\t- Therefore, we concluded that due to the chaotic and variable nature sports, especially with football, we cannot confindelty determine which games should be considered anomolies, so no rows are removed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_columns = ['Result', 'Season', 'Time', 'Week', 'G#']\n",
    "\n",
    "def get_numeric_columns(df, exclude_columns):\n",
    "    return sorted([col for col in df.select_dtypes(include=['float64', 'int64']).columns if col not in exclude_columns])\n",
    "\n",
    "numeric_columns = get_numeric_columns(df, exclude_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_distributions(data):\n",
    "\tnorm_params = stats.norm.fit(data) # Normal distribution\n",
    "\t\n",
    "\texp_params = stats.expon.fit(data) # Exponential distribution\n",
    "\t\n",
    "\tif (data > 0).all():\n",
    "\t\tlognorm_params = stats.lognorm.fit(data) # Log-Normal distribution (if all > 0)\n",
    "\t\treturn norm_params, exp_params, lognorm_params, True\n",
    "\telse:\n",
    "\t\treturn norm_params, exp_params, None, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = 4\n",
    "num_rows = int(np.ceil(len(numeric_columns) / num_cols))\n",
    "plt.figure(figsize=(num_cols * 4, num_rows * 4))\n",
    "\n",
    "for i, col in enumerate(numeric_columns, 1):\n",
    "\tdata = df[col]\n",
    "\tnorm_params, exp_params, lognorm_params, plot_lognorm = fit_distributions(data)\n",
    "\tplt.subplot(num_rows, num_cols, i)\n",
    "\tsns.histplot(data, kde=True, bins=20, color='blue', stat=\"density\")\n",
    "\txmin, xmax = plt.xlim()\n",
    "\tx = np.linspace(xmin, xmax, 100)\n",
    "\n",
    "\tp_norm = stats.norm.pdf(x, *norm_params) # Normal distribution\n",
    "\tplt.plot(x, p_norm, 'k-', label=f'Normal fit')\n",
    "\n",
    "\tp_exp = stats.expon.pdf(x, *exp_params) # Exponential distribution\n",
    "\tplt.plot(x, p_exp, 'r-', label=f'Exponential fit')\n",
    "\n",
    "\tif plot_lognorm:\n",
    "\t\tp_lognorm = stats.lognorm.pdf(x, *lognorm_params) # Log-Normal distribution (if all > 0)\n",
    "\t\tplt.plot(x, p_lognorm, 'g-', label=f'Log-Normal fit') \n",
    "\n",
    "\tplt.title(f'Distribution of {col}')\n",
    "\tplt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "exponential_features = ['Yds.1', 'Yds.3']\n",
    "normal_features = [col for col in numeric_columns if col not in exponential_features and col not in ['Result', 'Season', 'Time', 'Week', 'G#']]\n",
    "\n",
    "\n",
    "normal_data = df[normal_features]\n",
    "exponential_data = df[exponential_features]\n",
    "\n",
    "normal_data_standardized = normal_data.apply(zscore)\n",
    "exponential_data_log = np.log1p(exponential_data)\n",
    "exponential_data_log_standardized = exponential_data_log.apply(zscore)\n",
    "\n",
    "normal_anomalies_3 = (np.abs(normal_data_standardized) > 3).any(axis=1)\n",
    "normal_anomalies_4 = (np.abs(normal_data_standardized) > 4).any(axis=1)\n",
    "exponential_anomalies_3 = (np.abs(exponential_data_log_standardized) > 3).any(axis=1)\n",
    "exponential_anomalies_4 = (np.abs(exponential_data_log_standardized) > 4).any(axis=1)\n",
    "final_anomalies_3 = normal_anomalies_3 | exponential_anomalies_3\n",
    "final_anomalies_4 = normal_anomalies_4 | exponential_anomalies_4\n",
    "\n",
    "print(f\"Anomalies detected (threshold = 3): {final_anomalies_3.mean() * 100:.2f}%\")\n",
    "print(f\"Anomalies detected (threshold = 4): {final_anomalies_4.mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(normal_data_standardized.values.flatten(), bins=50, alpha=0.7, label=\"Normal Features\")\n",
    "plt.hist(exponential_data_log_standardized.values.flatten(), bins=50, alpha=0.7, label=\"Exponential Features\")\n",
    "plt.title(\"Distribution of Z-scores\")\n",
    "plt.xlabel(\"Z-score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df.copy()\n",
    "temp_df['Anomaly'] = final_anomalies_4.astype(int)\n",
    "anomalous_rows = temp_df[temp_df['Anomaly'] == 1]\n",
    "anomalous_rows.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Correlation Analysis**\n",
    "\n",
    "Correlation analysis helps to guide out feature engineering. It is useful for detecting irrelavent information and reducing dimensionality. To do so, we did the following:\n",
    "- Correlation of each column with 'Result'\n",
    "\t- Result only had a high correlation with PtDif, which makes sense as that's what determines the winner\n",
    "\t- Inc and Int dont seem to be correlated to Result\n",
    "- Correlation of each column with every other column (threshold = 0.7)\n",
    "\t- There seems to be several stats which are very highly correlated to each other, mostly due to how they are calculated\n",
    "\t- 'G#' and 'Week': expected due to both being time based, but don't seem to be hihgly correlated to any stat nor the result\n",
    "\t- A lot of the *Y/A are hihgly coorrelated, since it's mostly calcualtions from the total yards\n",
    "\t- 'Rate' also seems to be highly correlated to multiple other stats, also due to how rate is calculated\n",
    "\t- There is also a pattern of overall stat and stat %, which are high correlated and may be redundant\n",
    "- Correlation of each column with 'Y/P'\n",
    "\t- NY/A, ANY/A, AY/A, Y/A, Y/C, and Yds are all highly coorelated with 'Y/P'\n",
    "- Correlation of each column with 'DY/P'\n",
    "\t- 'DY/P' does not seem to be highly coorelated to any stat\n",
    "- Correlation of each column with 'Rate'\n",
    "\t- 'Rate' is decently correlated to stats related to TD, cmps, yards, and ints, which are used to calculate it\n",
    "- Correlation of each column with 'Yds'\n",
    "\t- 'Yds' is hihgly correlated to stats such as Cmp and tot\n",
    "- Correlation of each column with 'Yds.1'\n",
    "\t- Yards lost to sacks is strongly correlated to the num of sacks \"Sk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "numeric_data = df[numeric_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Compute the correlation matrix\n",
    "correlation_matrix = numeric_data.corr()\n",
    "\n",
    "# Step 2: Mask the upper triangle to avoid duplicate correlations (i.e., A vs B and B vs A)\n",
    "import numpy as np\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "# Step 3: Extract pairs of features with strong correlations (e.g., |correlation| > 0.7)\n",
    "threshold = 0.7\n",
    "strong_correlations = correlation_matrix.where(mask).stack().reset_index()\n",
    "strong_correlations.columns = ['Feature 1', 'Feature 2', 'Correlation']\n",
    "\n",
    "# Step 4: Filter strong correlations above the threshold (both positive and negative)\n",
    "strong_correlations = strong_correlations[strong_correlations['Correlation'].abs() > threshold]\n",
    "\n",
    "# Step 5: Remove self-correlations (Feature 1 and Feature 2 being the same)\n",
    "strong_correlations = strong_correlations[strong_correlations['Feature 1'] != strong_correlations['Feature 2']]\n",
    "\n",
    "# Step 6: Sort the correlations by absolute value\n",
    "strong_correlations['abs_correlation'] = strong_correlations['Correlation'].abs()\n",
    "strong_correlations_sorted = strong_correlations.sort_values(by='abs_correlation', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Step 7: Display the result\n",
    "print(strong_correlations_sorted[['Feature 1', 'Feature 2', 'Correlation']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlations_with_feature(feature_name):\n",
    "\tcorrelations = numeric_data.corrwith(df[feature_name])\n",
    "\tcorrelations = correlations.reset_index()\n",
    "\n",
    "\tcorrelations.columns = ['Feature', 'Correlation with ' + feature_name]\n",
    "\tcorrelations['abs_correlation'] = correlations['Correlation with ' + feature_name].abs()\n",
    "\n",
    "\tcorrelations_sorted = correlations.sort_values(by='abs_correlation', ascending=False).reset_index(drop=True)\n",
    "\tprint(correlations_sorted[['Feature', 'Correlation with ' + feature_name]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_with_feature('Result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_with_feature('Week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_with_feature('G#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_with_feature('Y/P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_with_feature('DY/P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_with_feature('Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_with_feature('Yds.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Selection & Engineering**\n",
    "\n",
    "Feature selection and engineering help to identify the most relevant variables (reduces dimentionality) and transform raw data into informative features, improving model accuracy, reducing complexity, and preventing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Feature Selection**\n",
    "\n",
    "For our feature selection, we used both the data from the correlation analysis as well as logic and previous experience with the sport. \n",
    "\n",
    "The general method is to train the model on each game with the format of<br>\n",
    "[General Game Data | Team 1 Stats| Team 2 Stats | Win/Loss]\n",
    "\n",
    "Since each game is presented twice in the data set (mirror for each team), we can simply get the data of team 1 for each game and then merge\n",
    "\n",
    "General Game Data:\n",
    "- Season\n",
    "- Date\n",
    "- Team\n",
    "- Opp\n",
    "- Away\n",
    "\n",
    "Win/Loss:\n",
    "- Result\n",
    "\n",
    "Team 1 Stats Included:\n",
    "- Pts: Generally important for a win\n",
    "- PtDif: How much they won/lost by\n",
    "- TO: Generally important for a win\n",
    "- Rate: Summarizes many important stats for a game (NFL rating)\n",
    "- Y/P: Generally important for a win, strongly correlated to other stats, serves as a summary\n",
    "- DY/P: Generally important for a win\n",
    "- ToP: Generally important for a win\n",
    "- Sk: Generally detrimental to a win\n",
    "- Yds.1: Sacked yards: Generally detrimental to a win\n",
    "- Att: Rushing attempts: generally a positive sign of performace\n",
    "- Rush_Yds: Generally important for a win\n",
    "\n",
    "Team 1 Stats Excluded:\n",
    "- Rate.1: A different rating system to the NFL rating, removed for consistency\n",
    "- NY/A: Strongly correlated to Y/P, redundant\n",
    "- ANY/A: Strongly correlated to Y/P, redundant\n",
    "- AY/A: Strongly correlated to Y/P, redundant\n",
    "- Y/A: Strongly correlated to Y/P, redundant\n",
    "- Y/C: Strongly correlated to Y/P, redundant\n",
    "- Cmp: Strongly correlated to Yds, redundant\n",
    "- Inc: reflected in Y/P\n",
    "- Int: reflected in DY/P\n",
    "- Rush_Y/A: reflected in Att and Rush_Yds\n",
    "- TD: Reflected in Pts\n",
    "- Yds: Reflected in Y/P\n",
    "- Att.2: Reflected in Y/P\n",
    "\n",
    "Team 2 Stats (All Excluded):\n",
    "- Att.3\n",
    "- Cmp%.1\n",
    "- Cmp.1\n",
    "- Int.1\n",
    "- Sk.1\n",
    "- Tot.1\n",
    "- TD.2\n",
    "- TD.3\n",
    "- Y/A.1\n",
    "- Yds.2\n",
    "- Yds.3\n",
    "- Opp_Rush_Yds\n",
    "- Att.1\n",
    "- TD.1\n",
    "- TO.1\n",
    "- PtsO\n",
    "\n",
    "Excluded:\n",
    "- Time: Irrelavent\n",
    "- Week: Irrelavent\n",
    "- G#: Irrelavent\n",
    "- Day: Irrelavent\n",
    "- Cmp%: Strongly correlated to Cmp, redundant\n",
    "- Int%: Strongly correlated to Int, redundant\n",
    "- Sk%: Strongly correlated to Sk, redundant\n",
    "- TD%: Strongly correlated to TD, redundant\n",
    "- Ply: Irrelavent, total for both teams\n",
    "- DPly: Irrelavent, total for both teams\n",
    "- PC: Irrelavent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, in the end we have:\n",
    "\n",
    "General Game Data:\n",
    "- Season -> Season\n",
    "- Date -> Date\n",
    "- Team -> Team1\n",
    "- Opp -> Team2\n",
    "- Away -> Home\n",
    "\n",
    "Win/Loss:\n",
    "- Result -> Result\n",
    "\n",
    "Team 1 Stats Included:\n",
    "- Pts -> Team1Pts\n",
    "- PtDif -> Team1PtDiff\n",
    "- TO -> Team1TM\n",
    "- Rate -> Team1Rating\n",
    "- Y/P -> Team1Y/P\n",
    "- DY/P -> Team1DY/P\n",
    "- ToP -> Team1ToP\n",
    "- Sk -> Team1Sks\n",
    "- Yds.1 -> Team1SkYds\n",
    "- Att -> Team1RushAtt\n",
    "- Rush_Yds -> Team1RushYds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Date</th>\n",
       "      <th>Team1</th>\n",
       "      <th>Team2</th>\n",
       "      <th>Home</th>\n",
       "      <th>Team1Pts</th>\n",
       "      <th>Team1PtDiff</th>\n",
       "      <th>Team1TM</th>\n",
       "      <th>Team1Rating</th>\n",
       "      <th>Team1Y/P</th>\n",
       "      <th>Team1DY/P</th>\n",
       "      <th>Team1ToP</th>\n",
       "      <th>Team1Sks</th>\n",
       "      <th>Team1SkYds</th>\n",
       "      <th>Team1RushAtt</th>\n",
       "      <th>Team1RushYds</th>\n",
       "      <th>Team1Won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>DET</td>\n",
       "      <td>GNB</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>109.7</td>\n",
       "      <td>5.14</td>\n",
       "      <td>6.62</td>\n",
       "      <td>2166</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>GNB</td>\n",
       "      <td>DET</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>111.7</td>\n",
       "      <td>6.62</td>\n",
       "      <td>5.14</td>\n",
       "      <td>1434</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>DEN</td>\n",
       "      <td>CLE</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>65.7</td>\n",
       "      <td>6.56</td>\n",
       "      <td>6.57</td>\n",
       "      <td>1670</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>CLE</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>-9</td>\n",
       "      <td>-1</td>\n",
       "      <td>88.1</td>\n",
       "      <td>6.57</td>\n",
       "      <td>6.56</td>\n",
       "      <td>1930</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>JAX</td>\n",
       "      <td>HOU</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>83.0</td>\n",
       "      <td>5.57</td>\n",
       "      <td>5.34</td>\n",
       "      <td>1663</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season       Date Team1 Team2  Home  Team1Pts  Team1PtDiff  Team1TM  \\\n",
       "0    2024 2024-12-05   DET   GNB     0        34            3        0   \n",
       "1    2024 2024-12-05   GNB   DET     1        31           -3        0   \n",
       "2    2024 2024-12-02   DEN   CLE     0        41            9        1   \n",
       "3    2024 2024-12-02   CLE   DEN     1        32           -9       -1   \n",
       "4    2024 2024-12-01   JAX   HOU     0        20           -3       -1   \n",
       "\n",
       "   Team1Rating  Team1Y/P  Team1DY/P  Team1ToP  Team1Sks  Team1SkYds  \\\n",
       "0        109.7      5.14       6.62      2166         1           3   \n",
       "1        111.7      6.62       5.14      1434         1           7   \n",
       "2         65.7      6.56       6.57      1670         0           0   \n",
       "3         88.1      6.57       6.56      1930         3          22   \n",
       "4         83.0      5.57       5.34      1663         0           0   \n",
       "\n",
       "   Team1RushAtt  Team1RushYds  Team1Won  \n",
       "0            34           111         1  \n",
       "1            24            99         0  \n",
       "2            26           106         1  \n",
       "3            23            77         0  \n",
       "4            25            97         0  "
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your original DataFrame\n",
    "\n",
    "# Step 1: Create a new DataFrame with only the columns you want and rename them\n",
    "new_df = df[['Season', 'Date', 'Team', 'Opp', 'Away', 'Pts', 'PtDif', 'TO', 'Rate', 'Y/P', 'DY/P', 'ToP', 'Sk', 'Yds.1', 'Att', 'Rush_Yds', 'Result']].copy()\n",
    "\n",
    "# Step 2: Rename columns\n",
    "new_df.rename(columns={\n",
    "    'Season': 'Season',\n",
    "    'Date': 'Date',\n",
    "    'Team': 'Team1',\n",
    "    'Opp': 'Team2',\n",
    "    'Away': 'Home',\n",
    "    'Pts': 'Team1Pts',\n",
    "    'PtDif': 'Team1PtDiff',\n",
    "    'TO': 'Team1TM',\n",
    "    'Rate': 'Team1Rating',\n",
    "    'Y/P': 'Team1Y/P',\n",
    "    'DY/P': 'Team1DY/P',\n",
    "    'ToP': 'Team1ToP',\n",
    "    'Sk': 'Team1Sks',\n",
    "    'Yds.1': 'Team1SkYds',\n",
    "    'Att': 'Team1RushAtt',\n",
    "    'Rush_Yds': 'Team1RushYds',\n",
    "    'Result': 'Team1Won'\n",
    "}, inplace=True)\n",
    "\n",
    "# Step 3: Modify the Home column (reverse 0 and 1 values)\n",
    "new_df['Home'] = new_df['Home'].apply(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "# Step 4: Add new columns for the margins\n",
    "# Assuming 'Yds.2' is Team2's total passing yards (you should adjust according to your actual column names)\n",
    "# Assuming 'Yds.3' is Team2's total sack yards (you should adjust according to your actual column names)\n",
    "# Assuming 'Opp_Rush_Yds' is Team2's rushing yards (you should adjust according to your actual column names)\n",
    "\n",
    "# Step 5: Preview the DataFrame\n",
    "new_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Engineering**\n",
    "\n",
    "Currently each row only tells the story of the stats of each team, they do not however, properly tell the difference between the teams besides PtDif, therefore, we will introduce 3 new features:\n",
    "- Pass: passing margin\n",
    "\t- Yds - Yds.2\n",
    "- Rush: rushing margin\n",
    "\t- Rush_Yds - Opp_Rush_Yds\n",
    "- Sack: sack margin\n",
    "\t- Yds.1 - Yds.3\n",
    "\n",
    "These help tell the 'story' of how close the match really was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Date</th>\n",
       "      <th>Team1</th>\n",
       "      <th>Team2</th>\n",
       "      <th>Home</th>\n",
       "      <th>Team1Pts</th>\n",
       "      <th>Team1PtDiff</th>\n",
       "      <th>Team1TM</th>\n",
       "      <th>Team1Rating</th>\n",
       "      <th>Team1Y/P</th>\n",
       "      <th>Team1DY/P</th>\n",
       "      <th>Team1ToP</th>\n",
       "      <th>Team1Sks</th>\n",
       "      <th>Team1SkYds</th>\n",
       "      <th>Team1RushAtt</th>\n",
       "      <th>Team1RushYds</th>\n",
       "      <th>Team1Won</th>\n",
       "      <th>Team1PYM</th>\n",
       "      <th>Team1RYM</th>\n",
       "      <th>Team1YM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>DET</td>\n",
       "      <td>GNB</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>109.7</td>\n",
       "      <td>5.14</td>\n",
       "      <td>6.62</td>\n",
       "      <td>2166</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>12</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>GNB</td>\n",
       "      <td>DET</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>111.7</td>\n",
       "      <td>6.62</td>\n",
       "      <td>5.14</td>\n",
       "      <td>1434</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>-81</td>\n",
       "      <td>-12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>DEN</td>\n",
       "      <td>CLE</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>65.7</td>\n",
       "      <td>6.56</td>\n",
       "      <td>6.57</td>\n",
       "      <td>1670</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>-181</td>\n",
       "      <td>29</td>\n",
       "      <td>-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>CLE</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>-9</td>\n",
       "      <td>-1</td>\n",
       "      <td>88.1</td>\n",
       "      <td>6.57</td>\n",
       "      <td>6.56</td>\n",
       "      <td>1930</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>-29</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>JAX</td>\n",
       "      <td>HOU</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>83.0</td>\n",
       "      <td>5.57</td>\n",
       "      <td>5.34</td>\n",
       "      <td>1663</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>-11</td>\n",
       "      <td>-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season       Date Team1 Team2  Home  Team1Pts  Team1PtDiff  Team1TM  \\\n",
       "0    2024 2024-12-05   DET   GNB     0        34            3        0   \n",
       "1    2024 2024-12-05   GNB   DET     1        31           -3        0   \n",
       "2    2024 2024-12-02   DEN   CLE     0        41            9        1   \n",
       "3    2024 2024-12-02   CLE   DEN     1        32           -9       -1   \n",
       "4    2024 2024-12-01   JAX   HOU     0        20           -3       -1   \n",
       "\n",
       "   Team1Rating  Team1Y/P  Team1DY/P  Team1ToP  Team1Sks  Team1SkYds  \\\n",
       "0        109.7      5.14       6.62      2166         1           3   \n",
       "1        111.7      6.62       5.14      1434         1           7   \n",
       "2         65.7      6.56       6.57      1670         0           0   \n",
       "3         88.1      6.57       6.56      1930         3          22   \n",
       "4         83.0      5.57       5.34      1663         0           0   \n",
       "\n",
       "   Team1RushAtt  Team1RushYds  Team1Won  Team1PYM  Team1RYM  Team1YM  \n",
       "0            34           111         1        81        12       -4  \n",
       "1            24            99         0       -81       -12        4  \n",
       "2            26           106         1      -181        29      -22  \n",
       "3            23            77         0       181       -29       22  \n",
       "4            25            97         0        58       -11      -24  "
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['Team1PYM'] = df['Yds'] - df['Yds.2']\n",
    "new_df['Team1RYM'] = df['Rush_Yds'] - df['Opp_Rush_Yds']\n",
    "new_df['Team1YM'] = df['Yds.1'] - df['Yds.3']\n",
    "\n",
    "new_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Date</th>\n",
       "      <th>Team1</th>\n",
       "      <th>Team2</th>\n",
       "      <th>Home</th>\n",
       "      <th>Team1Pts</th>\n",
       "      <th>Team2Pts</th>\n",
       "      <th>Team1PtDiff</th>\n",
       "      <th>Team2PtDiff</th>\n",
       "      <th>Team1TM</th>\n",
       "      <th>Team2TM</th>\n",
       "      <th>Team1Rating</th>\n",
       "      <th>Team2Rating</th>\n",
       "      <th>Team1Y/P</th>\n",
       "      <th>Team2Y/P</th>\n",
       "      <th>Team1DY/P</th>\n",
       "      <th>Team2DY/P</th>\n",
       "      <th>Team1ToP</th>\n",
       "      <th>Team2ToP</th>\n",
       "      <th>Team1Sks</th>\n",
       "      <th>Team2Sks</th>\n",
       "      <th>Team1SkYds</th>\n",
       "      <th>Team2SkYds</th>\n",
       "      <th>Team1RushAtt</th>\n",
       "      <th>Team2RushAtt</th>\n",
       "      <th>Team1RushYds</th>\n",
       "      <th>Team2RushYds</th>\n",
       "      <th>Team1PYM</th>\n",
       "      <th>Team2PYM</th>\n",
       "      <th>Team1RYM</th>\n",
       "      <th>Team2RYM</th>\n",
       "      <th>Team1YM</th>\n",
       "      <th>Team2YM</th>\n",
       "      <th>Team1Won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>DET</td>\n",
       "      <td>GNB</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.7</td>\n",
       "      <td>111.7</td>\n",
       "      <td>5.14</td>\n",
       "      <td>6.62</td>\n",
       "      <td>6.62</td>\n",
       "      <td>5.14</td>\n",
       "      <td>2166</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>34</td>\n",
       "      <td>24.0</td>\n",
       "      <td>111</td>\n",
       "      <td>99.0</td>\n",
       "      <td>81</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>GNB</td>\n",
       "      <td>DET</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.7</td>\n",
       "      <td>109.7</td>\n",
       "      <td>6.62</td>\n",
       "      <td>5.14</td>\n",
       "      <td>5.14</td>\n",
       "      <td>6.62</td>\n",
       "      <td>1434</td>\n",
       "      <td>2166.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24</td>\n",
       "      <td>34.0</td>\n",
       "      <td>99</td>\n",
       "      <td>111.0</td>\n",
       "      <td>-81</td>\n",
       "      <td>81.0</td>\n",
       "      <td>-12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>DEN</td>\n",
       "      <td>CLE</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>88.1</td>\n",
       "      <td>6.56</td>\n",
       "      <td>6.57</td>\n",
       "      <td>6.57</td>\n",
       "      <td>6.56</td>\n",
       "      <td>1670</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26</td>\n",
       "      <td>23.0</td>\n",
       "      <td>106</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-181</td>\n",
       "      <td>181.0</td>\n",
       "      <td>29</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>CLE</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.1</td>\n",
       "      <td>65.7</td>\n",
       "      <td>6.57</td>\n",
       "      <td>6.56</td>\n",
       "      <td>6.56</td>\n",
       "      <td>6.57</td>\n",
       "      <td>1930</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>26.0</td>\n",
       "      <td>77</td>\n",
       "      <td>106.0</td>\n",
       "      <td>181</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-29</td>\n",
       "      <td>29.0</td>\n",
       "      <td>22</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>JAX</td>\n",
       "      <td>HOU</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>95.5</td>\n",
       "      <td>5.57</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.57</td>\n",
       "      <td>1663</td>\n",
       "      <td>1937.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25</td>\n",
       "      <td>25.0</td>\n",
       "      <td>97</td>\n",
       "      <td>108.0</td>\n",
       "      <td>58</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-24</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>CIN</td>\n",
       "      <td>PIT</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>112.7</td>\n",
       "      <td>126.4</td>\n",
       "      <td>6.58</td>\n",
       "      <td>7.88</td>\n",
       "      <td>7.88</td>\n",
       "      <td>6.58</td>\n",
       "      <td>1731</td>\n",
       "      <td>1869.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15</td>\n",
       "      <td>26.0</td>\n",
       "      <td>93</td>\n",
       "      <td>110.0</td>\n",
       "      <td>-128</td>\n",
       "      <td>128.0</td>\n",
       "      <td>-17</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>TAM</td>\n",
       "      <td>CAR</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.7</td>\n",
       "      <td>83.4</td>\n",
       "      <td>5.78</td>\n",
       "      <td>5.40</td>\n",
       "      <td>5.40</td>\n",
       "      <td>5.78</td>\n",
       "      <td>2371</td>\n",
       "      <td>1659.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>9.0</td>\n",
       "      <td>39</td>\n",
       "      <td>21.0</td>\n",
       "      <td>236</td>\n",
       "      <td>78.0</td>\n",
       "      <td>-80</td>\n",
       "      <td>80.0</td>\n",
       "      <td>158</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>22</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>SFO</td>\n",
       "      <td>BUF</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-25</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>74.8</td>\n",
       "      <td>138.9</td>\n",
       "      <td>5.09</td>\n",
       "      <td>6.64</td>\n",
       "      <td>6.64</td>\n",
       "      <td>5.09</td>\n",
       "      <td>1593</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>38.0</td>\n",
       "      <td>153</td>\n",
       "      <td>220.0</td>\n",
       "      <td>-66</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-67</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>LAR</td>\n",
       "      <td>NOR</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.2</td>\n",
       "      <td>85.9</td>\n",
       "      <td>5.85</td>\n",
       "      <td>4.81</td>\n",
       "      <td>4.81</td>\n",
       "      <td>5.85</td>\n",
       "      <td>1643</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>31.0</td>\n",
       "      <td>156</td>\n",
       "      <td>143.0</td>\n",
       "      <td>-18</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>17</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>ATL</td>\n",
       "      <td>LAC</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>87.2</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.55</td>\n",
       "      <td>2155</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11</td>\n",
       "      <td>19.0</td>\n",
       "      <td>37</td>\n",
       "      <td>17.0</td>\n",
       "      <td>116</td>\n",
       "      <td>56.0</td>\n",
       "      <td>103</td>\n",
       "      <td>-103.0</td>\n",
       "      <td>60</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season       Date Team1 Team2  Home  Team1Pts  Team2Pts  Team1PtDiff  \\\n",
       "0    2024 2024-12-05   DET   GNB     0        34      31.0            3   \n",
       "1    2024 2024-12-05   GNB   DET     1        31      34.0           -3   \n",
       "2    2024 2024-12-02   DEN   CLE     0        41      32.0            9   \n",
       "3    2024 2024-12-02   CLE   DEN     1        32      41.0           -9   \n",
       "4    2024 2024-12-01   JAX   HOU     0        20      23.0           -3   \n",
       "5    2024 2024-12-01   CIN   PIT     0        38      44.0           -6   \n",
       "6    2024 2024-12-01   TAM   CAR     1        26      23.0            3   \n",
       "7    2024 2024-12-01   SFO   BUF     1        10      35.0          -25   \n",
       "8    2024 2024-12-01   LAR   NOR     1        21      14.0            7   \n",
       "9    2024 2024-12-01   ATL   LAC     0        13      17.0           -4   \n",
       "\n",
       "   Team2PtDiff  Team1TM  Team2TM  Team1Rating  Team2Rating  Team1Y/P  \\\n",
       "0         -3.0        0      0.0        109.7        111.7      5.14   \n",
       "1          3.0        0      0.0        111.7        109.7      6.62   \n",
       "2         -9.0        1     -1.0         65.7         88.1      6.56   \n",
       "3          9.0       -1      1.0         88.1         65.7      6.57   \n",
       "4          3.0       -1      1.0         83.0         95.5      5.57   \n",
       "5          6.0       -2      2.0        112.7        126.4      6.58   \n",
       "6         -3.0       -1      1.0         70.7         83.4      5.78   \n",
       "7         25.0       -3      3.0         74.8        138.9      5.09   \n",
       "8         -7.0        0      0.0        110.2         85.9      5.85   \n",
       "9          4.0       -3      3.0         40.0         87.2      4.55   \n",
       "\n",
       "   Team2Y/P  Team1DY/P  Team2DY/P  Team1ToP  Team2ToP  Team1Sks  Team2Sks  \\\n",
       "0      6.62       6.62       5.14      2166    1434.0         1       1.0   \n",
       "1      5.14       5.14       6.62      1434    2166.0         1       1.0   \n",
       "2      6.57       6.57       6.56      1670    1930.0         0       3.0   \n",
       "3      6.56       6.56       6.57      1930    1670.0         3       0.0   \n",
       "4      5.34       5.34       5.57      1663    1937.0         0       2.0   \n",
       "5      7.88       7.88       6.58      1731    1869.0         4       2.0   \n",
       "6      5.40       5.40       5.78      2371    1659.0         4       1.0   \n",
       "7      6.64       6.64       5.09      1593    2007.0         2       0.0   \n",
       "8      4.81       4.81       5.85      1643    1957.0         2       0.0   \n",
       "9      4.07       4.07       4.55      2155    1445.0         1       5.0   \n",
       "\n",
       "   Team1SkYds  Team2SkYds  Team1RushAtt  Team2RushAtt  Team1RushYds  \\\n",
       "0           3         7.0            34          24.0           111   \n",
       "1           7         3.0            24          34.0            99   \n",
       "2           0        22.0            26          23.0           106   \n",
       "3          22         0.0            23          26.0            77   \n",
       "4           0        24.0            25          25.0            97   \n",
       "5          27         4.0            15          26.0            93   \n",
       "6          31         9.0            39          21.0           236   \n",
       "7           8         0.0            27          38.0           153   \n",
       "8          17         0.0            29          31.0           156   \n",
       "9          11        19.0            37          17.0           116   \n",
       "\n",
       "   Team2RushYds  Team1PYM  Team2PYM  Team1RYM  Team2RYM  Team1YM  Team2YM  \\\n",
       "0          99.0        81     -81.0        12     -12.0       -4      4.0   \n",
       "1         111.0       -81      81.0       -12      12.0        4     -4.0   \n",
       "2          77.0      -181     181.0        29     -29.0      -22     22.0   \n",
       "3         106.0       181    -181.0       -29      29.0       22    -22.0   \n",
       "4         108.0        58     -58.0       -11      11.0      -24     24.0   \n",
       "5         110.0      -128     128.0       -17      17.0       23    -23.0   \n",
       "6          78.0       -80      80.0       158    -158.0       22    -22.0   \n",
       "7         220.0       -66      66.0       -67      67.0        8     -8.0   \n",
       "8         143.0       -18      18.0        13     -13.0       17    -17.0   \n",
       "9          56.0       103    -103.0        60     -60.0       -8      8.0   \n",
       "\n",
       "   Team1Won  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         0  \n",
       "5         0  \n",
       "6         1  \n",
       "7         0  \n",
       "8         1  \n",
       "9         0  "
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'new_df' is your original DataFrame\n",
    "\n",
    "# Step 1: Create a copy of the DataFrame and rename the columns to represent Team2's perspective\n",
    "df_shifted = new_df.copy()\n",
    "\n",
    "# Rename columns to reflect Team2's perspective (shifted stats)\n",
    "df_shifted.rename(columns={\n",
    "    'Team1': 'Team2',\n",
    "    'Team2': 'Team1',\n",
    "    'Team1Pts': 'Team2Pts',\n",
    "    'Team1PtDiff': 'Team2PtDiff',\n",
    "    'Team1TM': 'Team2TM',\n",
    "    'Team1Rating': 'Team2Rating',\n",
    "    'Team1Y/P': 'Team2Y/P',\n",
    "    'Team1DY/P': 'Team2DY/P',\n",
    "    'Team1ToP': 'Team2ToP',\n",
    "    'Team1Sks': 'Team2Sks',\n",
    "    'Team1SkYds': 'Team2SkYds',\n",
    "    'Team1RushAtt': 'Team2RushAtt',\n",
    "    'Team1RushYds': 'Team2RushYds',\n",
    "    'Team1PYM': 'Team2PYM',\n",
    "    'Team1RYM': 'Team2RYM',\n",
    "    'Team1YM': 'Team2YM',\n",
    "}, inplace=True)\n",
    "\n",
    "# Step 2: Merge the original DataFrame with the shifted DataFrame based on Date, Team1, and Team2\n",
    "merged_df = pd.merge(new_df, df_shifted, on=['Date', 'Team1', 'Team2'], how='left', suffixes=('', '_Team2'))\n",
    "\n",
    "# Step 3: Clean up the DataFrame by selecting the relevant columns (no duplicate columns)\n",
    "merged_df = merged_df[['Season', 'Date', 'Team1', 'Team2', 'Home', \n",
    "                       'Team1Pts', 'Team2Pts', 'Team1PtDiff', 'Team2PtDiff', \n",
    "                       'Team1TM', 'Team2TM', 'Team1Rating', 'Team2Rating', \n",
    "                       'Team1Y/P', 'Team2Y/P', 'Team1DY/P', 'Team2DY/P',\n",
    "                       'Team1ToP', 'Team2ToP', 'Team1Sks', 'Team2Sks', \n",
    "                       'Team1SkYds', 'Team2SkYds', 'Team1RushAtt', \n",
    "                       'Team2RushAtt', 'Team1RushYds', 'Team2RushYds', \n",
    "                       'Team1PYM', 'Team2PYM', 'Team1RYM', 'Team2RYM', \n",
    "                       'Team1YM', 'Team2YM', 'Team1Won']]\n",
    "\n",
    "# Now 'merged_df' will have the data for both teams in the same row, with the stats ported over correctly.\n",
    "\n",
    "merged_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('nfl_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
